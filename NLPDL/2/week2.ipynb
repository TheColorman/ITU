{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - NLP and Deep Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Annotation and POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment consists of 2 parts: first you annotate the data, then you compare your annotations against the annotations of another annotator. The annotation from the other annotator will be made available at 15:00 on 05-02-2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Annotation \n",
    "\n",
    "Find the file with your ITU username in `assignments/week2/pos-data/`. In this file, you will find 20\n",
    "sentences which are pre-tokenized and in conll format. Behind each word you are supposed to annotate the pos tag, with one tab in between. The final file should look like this:\n",
    "\n",
    "```\n",
    "Seriously\tADV\n",
    ":\tPUNCT\n",
    "do\tAUX\n",
    "not\tPART\n",
    "waste\tVERB\n",
    "your\tPRON\n",
    "time\tNOUN\n",
    ".\tPUNCT\n",
    "\n",
    "```\n",
    "\n",
    "You should use a tab between the word and its tag. Please check with the script posCheck.py\n",
    "whether the file format is correct. Usage: `python3 check-pos.py origFile annotatedFile`\n",
    "For annotation guidelines we refer to the slides and https://universaldependencies.org/u/pos/all.html. Alternatively, it might be helpful to look at example annotations, which are provided in:\n",
    "`assignments/week2/pos-data/ewt.train.txt`\n",
    "\n",
    "### Annotation tool\n",
    "If you prefer to work with an annotation tool instead of text files directly, you can use an annotation tool. You have to make sure to upload the data to LearnIt in the format described above though. I would recommend [Eevee](https://axelsorensen.github.io/EeveeTest/) because it is easy to set up and it works natively with this data format. An Eevee configuration file is available in the repo (`assignments/week2/eevee_pos.json`), and an explanation on how to use it is available from the [repo](https://github.com/AxelSorensenDev/Eevee). In short, you would have to import the configuration file with the ``Import task button``, and then import the POS data with the ``Import \"conll-like\" file`` button, then you can click ``Annotate`` and get started. The tool works completely in your browser, so make sure to download a backup of your data at a regular interval. Also, it has been made in collaboration with Rob, and any feedback is more than welcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Annotation Quality\n",
    "If you finished before the annotations of the other annotator are released (15:00) you can double check your annotations, already start implementing the following questions (with a dummy file) or ask a TA for the file. \n",
    "\n",
    "* a) Calculate the accuracy between you and the other annotator, how often did you agree?\n",
    "* b) Now implement Cohen’s Kappa score, and calculate the Kappa for your annotation sample. In which range\n",
    "does your Kappa score fall?\n",
    "* c) Take a closer look at the cases where you disagreed with the other annotator; are these disagreements due\n",
    "to ambiguity, or are there mistakes in the annotation? Would you classify your agreement in the same category as it falls in the standard kappa interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "with open(\"pos-data/alct.11.other.conll\") as f:\n",
    "    for line in f.readlines():\n",
    "        test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with open(\"pos-data/alct.11.conll\") as f:\n",
    "    for line in f.readlines():\n",
    "        out.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I\\tPRON\\n',\n",
       " 'look\\tVERB\\n',\n",
       " 'forward\\tADV\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'feedback\\tNOUN\\n',\n",
       " 'on\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'GISB\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'PS\\tNOUN\\n',\n",
       " '-\\tPUNCT\\n',\n",
       " 'Were\\tAUX\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'having\\tVERB\\n',\n",
       " 'phone\\tNOUN\\n',\n",
       " 'system\\tNOUN\\n',\n",
       " 'problems\\tNOUN\\n',\n",
       " 'this\\tDET\\n',\n",
       " 'morning\\tNOUN\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Further\\tADV\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'our\\tPRON\\n',\n",
       " 'conversation\\tNOUN\\n',\n",
       " ',\\tPUNCT\\n',\n",
       " 'please\\tINTJ\\n',\n",
       " 'see\\tVERB\\n',\n",
       " 'attached\\tVERB\\n',\n",
       " 'sample\\tNOUN\\n',\n",
       " 'agreements\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " '-\\tPUNCT\\n',\n",
       " 'ENRON-CPS\\tNOUN\\n',\n",
       " '(\\tX\\n',\n",
       " 'GISB\\tX\\n',\n",
       " 'rev1\\tX\\n',\n",
       " ')\\tX\\n',\n",
       " '.doc\\tX\\n',\n",
       " '\\n',\n",
       " 'I\\tPRON\\n',\n",
       " 'have\\tAUX\\n',\n",
       " 'sent\\tVERB\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'question\\tNOUN\\n',\n",
       " 're\\tADP\\n',\n",
       " 'on\\tADP\\n',\n",
       " 'line\\tNOUN\\n',\n",
       " 'trading\\tNOUN\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'that\\tDET\\n',\n",
       " 'area\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'They\\tPRON\\n',\n",
       " 'will\\tAUX\\n',\n",
       " 'contact\\tVERB\\n',\n",
       " 'you\\tPRON\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'I\\tPRON\\n',\n",
       " 'am\\tAUX\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'process\\tNOUN\\n',\n",
       " 'of\\tSCONJ\\n',\n",
       " 'reviewing\\tVERB\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'special\\tADJ\\n',\n",
       " 'provisions\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'clarify\\tVERB\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'all\\tNOUN\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'do\\tAUX\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'intend\\tVERB\\n',\n",
       " '10MM\\tNOUN\\n',\n",
       " 'for\\tADP\\n',\n",
       " 'ENA\\tPROPN\\n',\n",
       " 'as\\tADV\\n',\n",
       " 'well\\tADV\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'let\\tVERB\\n',\n",
       " 'me\\tPRON\\n',\n",
       " 'know\\tVERB\\n',\n",
       " 'if\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'need\\tVERB\\n',\n",
       " 'anything\\tPRON\\n',\n",
       " 'else\\tADJ\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Attached\\tVERB\\n',\n",
       " 'is\\tAUX\\n',\n",
       " 'an\\tDET\\n',\n",
       " 'image\\tNOUN\\n',\n",
       " 'of\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'GISB\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'As\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'see\\tVERB\\n',\n",
       " 'it\\tPRON\\n',\n",
       " 'was\\tAUX\\n',\n",
       " 'CES\\tNOUN\\n',\n",
       " 'acquired\\tVERB\\n',\n",
       " 'by\\tADP\\n',\n",
       " 'ENA\\tPROPN\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'asset\\tNOUN\\n',\n",
       " 'purchase\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'let\\tVERB\\n',\n",
       " 'me\\tPRON\\n',\n",
       " 'know\\tVERB\\n',\n",
       " 'how\\tADV\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'would\\tAUX\\n',\n",
       " 'like\\tVERB\\n',\n",
       " 'to\\tPART\\n',\n",
       " 'proceed\\tVERB\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'The\\tDET\\n',\n",
       " 'term\\tNOUN\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'Aggregate\\tADJ\\n',\n",
       " 'Transporter\\tNOUN\\n',\n",
       " 'Imbalance\\tNOUN\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'is\\tAUX\\n',\n",
       " 'located\\tVERB\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'several\\tADJ\\n',\n",
       " 'sections\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Could\\tAUX\\n',\n",
       " 'this\\tPRON\\n',\n",
       " 'be\\tAUX\\n',\n",
       " 'what\\tPRON\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'r\\tAUX\\n',\n",
       " 'referencing\\tVERB\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'See\\tVERB\\n',\n",
       " 'attached\\tVERB\\n',\n",
       " 'revised\\tVERB\\n',\n",
       " 'Article\\tNOUN\\n',\n",
       " '4.6\\tNUM\\n',\n",
       " 'Masters\\tNOUN\\n',\n",
       " 'below\\tADV\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'These\\tPRON\\n',\n",
       " 'look\\tVERB\\n',\n",
       " 'fine\\tADJ\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'me\\tPRON\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Go\\tVERB\\n',\n",
       " 'ahead\\tADV\\n',\n",
       " 'and\\tCCONJ\\n',\n",
       " 'forward\\tVERB\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'Brant\\tPROPN\\n',\n",
       " 'if\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'are\\tAUX\\n',\n",
       " 'ready\\tADJ\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'As\\tSCONJ\\n',\n",
       " 'discussed\\tVERB\\n',\n",
       " ',\\tPUNCT\\n',\n",
       " 'attached\\tVERB\\n',\n",
       " 'is\\tAUX\\n',\n",
       " 'a\\tDET\\n',\n",
       " 'GISB\\tNOUN\\n',\n",
       " 'draft\\tNOUN\\n',\n",
       " 'for\\tADP\\n',\n",
       " 'Pioneer\\tPROPN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Do\\tAUX\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'have\\tVERB\\n',\n",
       " 'this\\tDET\\n',\n",
       " 'information\\tNOUN\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Rudwell\\tPROPN\\n',\n",
       " 'Johnson\\tPROPN\\n',\n",
       " '/\\tPUNCT\\n',\n",
       " 'ENRON@enronXgate\\tX\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I\\tPRON\\n',\n",
       " 'look\\tVERB\\n',\n",
       " 'forward\\tADV\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'feedback\\tNOUN\\n',\n",
       " 'on\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'GISB\\tPROPN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'PS\\tNOUN\\n',\n",
       " '-\\tPUNCT\\n',\n",
       " 'Were\\tVERB\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'having\\tVERB\\n',\n",
       " 'phone\\tNOUN\\n',\n",
       " 'system\\tNOUN\\n',\n",
       " 'problems\\tNOUN\\n',\n",
       " 'this\\tDET\\n',\n",
       " 'morning\\tNOUN\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Further\\tADV\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'our\\tPRON\\n',\n",
       " 'conversation\\tNOUN\\n',\n",
       " ',\\tPUNCT\\n',\n",
       " 'please\\tINTJ\\n',\n",
       " 'see\\tVERB\\n',\n",
       " 'attached\\tADJ\\n',\n",
       " 'sample\\tNOUN\\n',\n",
       " 'agreements\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " '-\\tPUNCT\\n',\n",
       " 'ENRON-CPS\\tPROPN\\n',\n",
       " '(\\tPUNCT\\n',\n",
       " 'GISB\\tPROPN\\n',\n",
       " 'rev1\\tNOUN\\n',\n",
       " ')\\tPUNCT\\n',\n",
       " '.doc\\tX\\n',\n",
       " '\\n',\n",
       " 'I\\tPRON\\n',\n",
       " 'have\\tAUX\\n',\n",
       " 'sent\\tVERB\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'question\\tNOUN\\n',\n",
       " 're\\tADP\\n',\n",
       " 'on\\tADP\\n',\n",
       " 'line\\tNOUN\\n',\n",
       " 'trading\\tVERB\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'that\\tDET\\n',\n",
       " 'area\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'They\\tPRON\\n',\n",
       " 'will\\tAUX\\n',\n",
       " 'contact\\tVERB\\n',\n",
       " 'you\\tPRON\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'I\\tPRON\\n',\n",
       " 'am\\tAUX\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'process\\tNOUN\\n',\n",
       " 'of\\tADP\\n',\n",
       " 'reviewing\\tVERB\\n',\n",
       " 'your\\tPRON\\n',\n",
       " 'special\\tADJ\\n',\n",
       " 'provisions\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'clarify\\tVERB\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'all\\tDET\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'do\\tAUX\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'intend\\tVERB\\n',\n",
       " '10MM\\tNOUN\\n',\n",
       " 'for\\tADP\\n',\n",
       " 'ENA\\tPROPN\\n',\n",
       " 'as\\tADV\\n',\n",
       " 'well\\tADV\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'let\\tVERB\\n',\n",
       " 'me\\tPRON\\n',\n",
       " 'know\\tVERB\\n',\n",
       " 'if\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'need\\tVERB\\n',\n",
       " 'anything\\tPRON\\n',\n",
       " 'else\\tADJ\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Attached\\tVERB\\n',\n",
       " 'is\\tAUX\\n',\n",
       " 'an\\tDET\\n',\n",
       " 'image\\tNOUN\\n',\n",
       " 'of\\tADP\\n',\n",
       " 'the\\tDET\\n',\n",
       " 'GISB\\tPROPN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'As\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'see\\tVERB\\n',\n",
       " 'it\\tPRON\\n',\n",
       " 'was\\tPROPN\\n',\n",
       " 'CES\\tNOUN\\n',\n",
       " 'acquired\\tVERB\\n',\n",
       " 'by\\tADP\\n',\n",
       " 'ENA\\tPROPN\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'asset\\tNOUN\\n',\n",
       " 'purchase\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Please\\tINTJ\\n',\n",
       " 'let\\tVERB\\n',\n",
       " 'me\\tPRON\\n',\n",
       " 'know\\tVERB\\n',\n",
       " 'how\\tADV\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'would\\tAUX\\n',\n",
       " 'like\\tVERB\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'proceed\\tVERB\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'The\\tDET\\n',\n",
       " 'term\\tNOUN\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'Aggregate\\tNOUN\\n',\n",
       " 'Transporter\\tNOUN\\n',\n",
       " 'Imbalance\\tNOUN\\n',\n",
       " '\"\\tPUNCT\\n',\n",
       " 'is\\tAUX\\n',\n",
       " 'located\\tVERB\\n',\n",
       " 'in\\tADP\\n',\n",
       " 'several\\tADJ\\n',\n",
       " 'sections\\tNOUN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Could\\tAUX\\n',\n",
       " 'this\\tPRON\\n',\n",
       " 'be\\tAUX\\n',\n",
       " 'what\\tDET\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'r\\tVERB\\n',\n",
       " 'referencing\\tVERB\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'See\\tVERB\\n',\n",
       " 'attached\\tVERB\\n',\n",
       " 'revised\\tADJ\\n',\n",
       " 'Article\\tNOUN\\n',\n",
       " '4.6\\tNUM\\n',\n",
       " 'Masters\\tNOUN\\n',\n",
       " 'below\\tADP\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'These\\tPRON\\n',\n",
       " 'look\\tVERB\\n',\n",
       " 'fine\\tADJ\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'me\\tPRON\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Go\\tVERB\\n',\n",
       " 'ahead\\tADP\\n',\n",
       " 'and\\tCCONJ\\n',\n",
       " 'forward\\tADP\\n',\n",
       " 'to\\tADP\\n',\n",
       " 'Brant\\tPROPN\\n',\n",
       " 'if\\tSCONJ\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'are\\tVERB\\n',\n",
       " 'ready\\tVERB\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'As\\tSCONJ\\n',\n",
       " 'discussed\\tVERB\\n',\n",
       " ',\\tPUNCT\\n',\n",
       " 'attached\\tVERB\\n',\n",
       " 'is\\tVERB\\n',\n",
       " 'a\\tDET\\n',\n",
       " 'GISB\\tPROPN\\n',\n",
       " 'draft\\tNOUN\\n',\n",
       " 'for\\tADP\\n',\n",
       " 'Pioneer\\tPROPN\\n',\n",
       " '.\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Do\\tAUX\\n',\n",
       " 'you\\tPRON\\n',\n",
       " 'have\\tVERB\\n',\n",
       " 'this\\tPRON\\n',\n",
       " 'information\\tNOUN\\n',\n",
       " '?\\tPUNCT\\n',\n",
       " '\\n',\n",
       " 'Rudwell\\tPROPN\\n',\n",
       " 'Johnson\\tPROPN\\n',\n",
       " '/\\tSYM\\n',\n",
       " 'ENRON@enronXgate\\tX\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.86%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_labels(l):\n",
    "    labels = [i.strip() for i in l]\n",
    "    while \"\" in labels:\n",
    "        labels.remove(\"\")\n",
    "    labels = [i.split(\"\\t\")[1] for i in labels]\n",
    "    return np.array(labels)\n",
    "\n",
    "test_labels = get_labels(test)\n",
    "pred_labels = get_labels(out)\n",
    "\n",
    "TRU = sum(test_labels == pred_labels)\n",
    "TOT = len(test_labels)\n",
    "ACC = TRU / TOT\n",
    "print(f\"Accuracy: {ACC * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# i dont understand the kappa calculation yet and i just wanna get this done\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "k = cohen_kappa_score(test_labels, pred_labels)\n",
    "print(f\"Kappa score: {k:.2f}\") # basically the same as accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: GISB\tPROPN\n",
      "test: GISB\tNOUN\n",
      "pred: Were\tVERB\n",
      "test: Were\tAUX\n",
      "pred: attached\tADJ\n",
      "test: attached\tVERB\n",
      "pred: ENRON-CPS\tPROPN\n",
      "test: ENRON-CPS\tNOUN\n",
      "pred: (\tPUNCT\n",
      "test: (\tX\n",
      "pred: GISB\tPROPN\n",
      "test: GISB\tX\n",
      "pred: rev1\tNOUN\n",
      "test: rev1\tX\n",
      "pred: )\tPUNCT\n",
      "test: )\tX\n",
      "pred: trading\tVERB\n",
      "test: trading\tNOUN\n",
      "pred: of\tADP\n",
      "test: of\tSCONJ\n",
      "pred: all\tDET\n",
      "test: all\tNOUN\n",
      "pred: GISB\tPROPN\n",
      "test: GISB\tNOUN\n",
      "pred: was\tPROPN\n",
      "test: was\tAUX\n",
      "pred: to\tADP\n",
      "test: to\tPART\n",
      "pred: Aggregate\tNOUN\n",
      "test: Aggregate\tADJ\n",
      "pred: what\tDET\n",
      "test: what\tPRON\n",
      "pred: r\tVERB\n",
      "test: r\tAUX\n",
      "pred: revised\tADJ\n",
      "test: revised\tVERB\n",
      "pred: below\tADP\n",
      "test: below\tADV\n",
      "pred: ahead\tADP\n",
      "test: ahead\tADV\n",
      "pred: forward\tADP\n",
      "test: forward\tVERB\n",
      "pred: are\tVERB\n",
      "test: are\tAUX\n",
      "pred: ready\tVERB\n",
      "test: ready\tADJ\n",
      "pred: is\tVERB\n",
      "test: is\tAUX\n",
      "pred: GISB\tPROPN\n",
      "test: GISB\tNOUN\n",
      "pred: this\tPRON\n",
      "test: this\tDET\n",
      "pred: /\tSYM\n",
      "test: /\tPUNCT\n"
     ]
    }
   ],
   "source": [
    "for predl, testl in zip(out, test):\n",
    "    try:\n",
    "        p = predl.split(\"\\t\")[1]\n",
    "        t = testl.split(\"\\t\")[1]\n",
    "        if p != t:\n",
    "            print(\"pred:\", predl.strip())\n",
    "            print(\"test:\", testl.strip())\n",
    "    except:\n",
    "        pass\n",
    "# Most of the problems are me being wrong, but some things like ) being X instead of PUNCT and / being PUNCT instead of SYM is a difference in interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Generative and Discriminative Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Words as Features\n",
    "In this assignment, we will convert a text to a matrix of features for the purpose of language identification. We will use data from star-wars fandom wikipedia:\n",
    "* English [Wookipedia](https://starwars.fandom.com/wiki/Main_Page)  \n",
    "* Danish [Kraftens Arkiver](https://starwars.fandom.com/da/wiki) \n",
    "* Dutch [Yodapedia](https://starwars.fandom.com/da/wiki)\n",
    "\n",
    "We have already tokenized the data for you. The data can be read like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mess Hall IV was a mess hall on the Rebel Alliance space station Mako-Ta Space Docks .',\n",
       "  'Bibble , een bijzonder geleerd persoon , had een puntbaard en droeg zijn grijzend haar lang in de hals .',\n",
       "  'Een KYD-21 Blaster Pistol was het geliefkoosde wapen van Zam Wesell .',\n",
       "  \"Colonel Drefin appears on Quesh in the video game `` '' , released by BioWare in 2011 .\",\n",
       "  'Bane verliet zijn stad en zwoer om nooit terug te keren .'],\n",
       " ['en', 'nl', 'nl', 'en', 'nl'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_langid(path):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        tok = line.strip().split('\\t')\n",
    "        labels.append(tok[0])\n",
    "        text.append(tok[1])\n",
    "    return text, labels\n",
    "\n",
    "wooki_train_text, wooki_train_labels = load_langid('langid-data/wookipedia_langid.train.tok.txt')\n",
    "wooki_dev_text, wooki_dev_labels = load_langid('langid-data/wookipedia_langid.dev.tok.txt')\n",
    "wooki_dev_text[:5], wooki_dev_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Convert the train data to \"binary word features\". This means that every instance (sentence) is represented by a vector of binary values, each of which corresponds to a word. For example (features are on the columns, input on the rows):\n",
    "\n",
    "|             | hello | bye | there | here | ... |\n",
    "|-------------|-------|-----|-------|------|-----|\n",
    "| hello there | 1     | 0   | 1     | 0    |     |\n",
    "| bye bye     | 0     | 1   | 0     | 0    |     |\n",
    "\n",
    "\n",
    "Note that this means that you will end up with a matrix of size `(#data_instances, len(vocab))` where `vocab` contains your vocabulary (i.e. all the words in the train data), and the `#data_instances` is the number of input sentences (feel free to use numpy, torch or native python lists). This matrix will be filled with 0's and 1's, indicating which features are present in which instances.\n",
    "\n",
    "**Hint**: Start with two sentences, as it is much easier to debug (and with 1 sentence, you will have only 1s)\n",
    "\n",
    "b) Convert the dev data to the same features generated from the training data. Note that no new features can be introduced at this point, check whether the size of the matrix is `(#dev_instances, len(vocab))`.\n",
    "\n",
    "c) Write down what are the pros and cons of representing text as `BOW` (bag-of-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# a\n",
    "# gonna split words on spaces cause im lazy.\n",
    "vocab = np.unique(\" \".join(wooki_train_text).split(\" \"))\n",
    "train_matrix = np.zeros((len(wooki_train_labels), len(vocab)))\n",
    "for i, text in enumerate(wooki_train_text):\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        idx, = np.where(vocab == word)\n",
    "        train_matrix[i, idx] = 1\n",
    "train_matrix = train_matrix.astype(bool)\n",
    "\n",
    "# Make sure it works\n",
    "words = wooki_train_text[0].split(\" \")[:10]\n",
    "for word in words:\n",
    "    idx, np.where(vocab == word)\n",
    "    print(train_matrix[0, idx])\n",
    "print(train_matrix[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# b\n",
    "# do the exact same thing but for dev data\n",
    "dev_matrix = np.zeros((len(wooki_train_labels), len(vocab)))\n",
    "for i, text in enumerate(wooki_train_text):\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        try: # idx could error if unknown word\n",
    "            idx, = np.where(vocab == word)\n",
    "            dev_matrix[i, idx] = 1\n",
    "        except: pass\n",
    "dev_matrix = dev_matrix.astype(bool)\n",
    "\n",
    "# Make sure it works\n",
    "words = wooki_train_text[0].split(\" \")[:10]\n",
    "for word in words:\n",
    "    idx, np.where(vocab == word)\n",
    "    print(dev_matrix[0, idx])\n",
    "print(dev_matrix[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFor language identification? Not that many problems. Maybe the words of\\n2 languages are very close and you need the context of grammar to properly\\ndistinguish them. For other tasks, context is a lot more important, and\\nBOW removes all context.  \\n\\nThen there's also the problem of unseen words, if a word hasn't been seen\\nduring training data, it won't contribute anything when testing.\\n\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "\"\"\"\n",
    "For language identification? Not that many problems. Maybe the words of\n",
    "2 languages are very close and you need the context of grammar to properly\n",
    "distinguish them. For other tasks, context is a lot more important, and\n",
    "BOW removes all context.  \n",
    "\n",
    "Then there's also the problem of unseen words, if a word hasn't been seen\n",
    "during training data, it won't contribute anything when testing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Character n-grams\n",
    "Character n-grams can have some advantages over word-level features, as there can be more overlap and less unknown features. It is common to use a range of n-gram sizes, for example 3-6 is a common choice. Convert the following text to character n-grams, use a range of 1-3 (so unigrams, bigrams and trigrams). You do not have to make use of special start characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 'This is a fish'\n",
    "\n",
    "ngrams = []\n",
    "\n",
    "expected_output = ['T', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', ' ', 'f', 'i', 's', 'h', 'Th', 'hi', 'is', 's ', ' i', 'is', 's ', ' a', 'a ', ' f', 'fi', 'is', 'sh', 'Thi', 'his', 'is ', 's i', ' is', 'is ', 's a', ' a ', 'a f', ' fi', 'fis', 'ish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' ' a' ' a ' ' f' ' fi' ' i' ' is' 'T' 'Th' 'Thi' 'a' 'a ' 'a f' 'f'\n",
      " 'fi' 'fis' 'h' 'hi' 'his' 'i' 'is' 'is ' 'ish' 's' 's ' 's a' 's i' 'sh']\n"
     ]
    }
   ],
   "source": [
    "ngrams = []\n",
    "for n in range(1, 4):\n",
    "    for i in range(len(input_data)):\n",
    "        ngrams.append(input_data[i:i+n])\n",
    "\n",
    "ngrams = np.unique(ngrams)\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes Classifier\n",
    "\n",
    "Solve the following exercises from [Chapter 4 of Speech and Language processing](https://web.stanford.edu/~jurafsky/slp3/4.pdf):\n",
    "\n",
    "a) Exercise 4.1 from J&M: (copied here for your convenience):\n",
    "\n",
    "Assume the following likelihoods for each word being part of a positive or\n",
    "negative movie review, and equal prior probabilities for each class.\n",
    "\n",
    "| feature         | pos | neg     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| I      |  0.09      |  0.16  |\n",
    "| always   | 0.07        | 0.06      |\n",
    "| like      | 0.29       | 0.06   |\n",
    "| foreign      | 0.04       | 0.15   |\n",
    "| films      |  0.08      | 0.11   |\n",
    "\n",
    "- What class will Naive Bayes assign to the sentence `“I always like foreign films.”`?\n",
    "\n",
    "b) Exercise 4.2 from J&M (copied here for your convenience):\n",
    "\n",
    "Given the following short movie reviews, each labeled with a genre, either comedy or action:\n",
    "\n",
    "1. fun, couple, love, love **comedy**\n",
    "\n",
    "2. fast, furious, shoot **action**\n",
    "\n",
    "3. couple, fly, fast, fun, fun **comedy**\n",
    "\n",
    "4. furious, shoot, shoot, fun **action**\n",
    "\n",
    "5. fly, fast, shoot, love **action**\n",
    "\n",
    "and a new document D:\n",
    "\n",
    "```\n",
    "fast, couple, shoot, fly\n",
    "```\n",
    "\n",
    "- Compute the most likely class for D. Assume a Naive Bayes classifier and use *add-1 smoothing* for the likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8464e-06 9.503999999999999e-06\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "pos = {\n",
    "    'I': 0.09,\n",
    "    'always': 0.07,\n",
    "    'like': 0.29,\n",
    "    'foreign': 0.04,\n",
    "    'films': 0.08\n",
    "}\n",
    "neg = {\n",
    "    'I': 0.16,\n",
    "    'always': 0.06,\n",
    "    'like': 0.06,\n",
    "    'foreign': 0.15,\n",
    "    'films': 0.11\n",
    "}\n",
    "\n",
    "def pr(text: str):\n",
    "    words = text.split(\" \")\n",
    "    p = np.prod([pos[word] for word in words])\n",
    "    n = np.prod([neg[word] for word in words])\n",
    "    return(p, n)\n",
    "\n",
    "def pred(text: str):\n",
    "    p, n = pr(text)\n",
    "    print(p, n)\n",
    "    if p > n:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "print(pred(\"I always like foreign films\")) # a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'comedy': [\"fun couple love love\", \"couple fly fast fun fun\"],\n",
    "    'action': [\"fast furious shoot\", \"furious shoot shoot fun\", \"fly fast shoot love\"]\n",
    "}\n",
    "\n",
    "def pr(word, cat):\n",
    "    d = \" \".join(data[cat]).split(\" \")\n",
    "                              # smoothing\n",
    "    wordcount = d.count(word) + 1\n",
    "    catcount  = len(d)        + len(np.unique(d))\n",
    "    return wordcount / catcount\n",
    "\n",
    "def pred(text):\n",
    "    cats = ['comedy', 'action']\n",
    "    words = text.split(\" \")\n",
    "    probs = []\n",
    "    for cat in cats:\n",
    "        probs.append(np.prod([pr(word, cat) for word in words]))\n",
    "    idx = np.argmax(probs)\n",
    "    return cats[idx]\n",
    "\n",
    "pred(\"fast couple shoot fly\")\n",
    "# Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Naive Bayes with BOW in sklearn \n",
    "\n",
    "In this assignment, we will focus on the task of language identification. You can use the data from assignment 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langid(path):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        tok = line.strip().split('\\t')\n",
    "        labels.append(tok[0])\n",
    "        text.append(tok[1])\n",
    "    return text, labels\n",
    "\n",
    "wooki_train_text, wooki_train_labels = load_langid('langid-data/wookipedia_langid.train.tok.txt')\n",
    "wooki_dev_text, wooki_dev_labels = load_langid('langid-data/wookipedia_langid.dev.tok.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Train a Naive Bayes classifier with character 3-6 grams, you can make use of the scikit-learn implementations for the n-grams ([CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), you can use the range and analyser parameters) as well as Naive Bayes ([MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)), note that there are multiple variations of Naive Bayes implementations in sklearn, the one discussed in the book/slides is the multinomial variant. \n",
    "\n",
    "**Note**: the input is a list of lists of features `x` and a list of corresponding gold labels `y`. Therefore, the following should hold `len(x) == len(y)` and their indices should match.\n",
    "Additionally, every instance in `x` should have the same length (the number of features).\n",
    "\n",
    "b) Run the classifier on the dev data. It is crucial that you ensure that the feature values have exactly the same order as during training. How well does it perform? (what is the accuracy?)\n",
    "\n",
    "**Note**: you cannot introduce new features here (!): you have to use the exact same features as the ones used during training.\n",
    "\n",
    "**Hint**: If the accuracy is lower than 50%, you are probably mixing up the feature order, either during training or during development or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 96.51\n",
      "Test accuracy: 95.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 6))\n",
    "X_train = vectorizer.fit_transform(wooki_train_text)\n",
    "X_test = vectorizer.transform(wooki_dev_text)\n",
    "y_train = wooki_train_labels\n",
    "y_test = wooki_dev_labels\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "train_preds = nb.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "\n",
    "test_preds = nb.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc*100:.2f}\")\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}\")\n",
    "# not bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 7. Discriminative Classifier with BOW\n",
    "\n",
    "a) Train a `logistic regression` classifier in a similar fashion. For more information, see: [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Does it outperform the naive bayes classifier?\n",
    "\n",
    "b) Now evaluate both classifiers (`logistic regression` and `naive bayes`) on the out-of-domain Bulbapedia data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulba_dev_text, bulba_dev_labels = load_langid('langid-data/bulbapedia_langid.dev.tok.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are the trends similar to the Wookipedia data? Is there a performance drop compared to the Wookipedia data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.90\n",
      "Test accuracy: 94.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_preds = lr.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "\n",
    "test_preds = lr.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc*100:.2f}\")\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}\")\n",
    "# interesting, logistic regressino overfit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 94.47\n",
      "Logistic Regression accuracy: 94.47\n"
     ]
    }
   ],
   "source": [
    "X_new = vectorizer.transform(bulba_dev_text)\n",
    "y_new = bulba_dev_labels\n",
    "\n",
    "for c, clf in zip([\"Naive Bayes\", \"Logistic Regression\"], [nb, lr]):\n",
    "    new_preds = clf.predict(X_new)\n",
    "    new_acc = accuracy_score(y_new, new_preds)\n",
    "\n",
    "    print(f\"{c} accuracy: {test_acc*100:.2f}\")\n",
    "# wow, same exact score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis\n",
    "There are two obvious ways to inspect the classifiers in more detail: by inspecting a confusion matrix and by\n",
    "examining the feature weights. Pick at least one of the following options:\n",
    "\n",
    "### Confusion matrix\n",
    "a) Plot a confusion matrix for the logistic regression BOW model trained in `7a)` when used on Bulbapedia data, and inspect the errors (it is not important how you visualize the results: a table, a figure, or even an ASCII table will suffice). \n",
    "Are there any interesting trends?\n",
    "\n",
    "### Feature weights\n",
    "In scikit-learn, you can inspect the internal weights given to each feature in the `.coef_` variable. \n",
    "\n",
    "a) Inspect the most important features for both the naive bayes and logistic regression classifiers. Are there any interesting differences?\n",
    "\n",
    "**Hint**: The weights are given per class, so you can either inspect three lists, or compute the average importance\n",
    "(make sure to use the absolute feature values for the average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new_preds = lr.predict(X_new)\n",
    "\n",
    "cm = confusion_matrix(y_new, new_preds, labels=lr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "# It really likes to label dutch as danish. Makes sense."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
