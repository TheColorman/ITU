{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - NLP and Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "# Lecture 7. RNN 1\n",
    "\n",
    "In assignments for this lecture we are going to implement an RNN POS tagger in Pytorch.\n",
    "\n",
    "You can use the following function for data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12543\n",
      "2000\n",
      "159\n"
     ]
    }
   ],
   "source": [
    "def read_conll_file(path):\n",
    "    \"\"\"\n",
    "    read in conll file\n",
    "    \n",
    "    :param path: path to read from\n",
    "    :returns: list with sequences of words and labels for each sentence\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue # skip comments\n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            current_words.append(tok[0])\n",
    "            current_tags.append(tok[1])\n",
    "        else:\n",
    "            if current_words:  # skip empty lines\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "    return data\n",
    "\n",
    "train_data = read_conll_file('pos-data/en_ewt-train.conll')\n",
    "dev_data = read_conll_file('pos-data/en_ewt-dev.conll')\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(dev_data))\n",
    "print(max([len(x[0]) for x in train_data ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data for use in PyTorch\n",
    "\n",
    "* a) Convert the data to a format that can be used in a Pytorch module. This means we require:\n",
    "\n",
    "  * training data: matrix of number of instances (12543) by the maximum sentence length (159), filled with word indices\n",
    "  * training labels: matrix of the same size, but filled with label indexes instead ( total of 17)\n",
    "  * the same two sets for the dev data (note that no word indices can be added anymore)\n",
    "  \n",
    "A special `<PAD>` token can be used for padding, for sentences shorter as 91 words. For the unknown words in the test set, you can use the `<PAD>` token as well.\n",
    "\n",
    "**HINT** It will be beneficial in the long run to make a function to convert your data to the right format, as you would have to do it for the train, dev and test sets, and for any other dataset you want to evaluate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12543, 159])\n",
      "tensor([[13649,  1305, 13605,  2380,    38,  7528,   102,  4731,  4455,    12,\n",
      "           107,    73,    99,  4321,    28, 13650,   107,   969,    38,   633,\n",
      "            28, 13651,  1525,    19,  4455,   720,   102, 13652, 13653,    15,\n",
      "            13,  8446, 12609,  8467, 13654,   559,  1927,   559,    12,    58,\n",
      "           387,   468,    99,    91,  2100,    60,    13,  8942,  2878,   138,\n",
      "         13655,   107, 13656,   151,  5030,    38,   431,   491,   538, 13605,\n",
      "          4136,   468,    99,  3039,    17,    13, 12512,    19,   559,    66,\n",
      "         13657,    19,  1305,   107, 13652,   559,     4,   559,    13,   178,\n",
      "           558,   196,   372,    12,    46,  4051,   372,    38, 13658,   133,\n",
      "           873,   559,    12,    66, 13620,   787, 13619,  3718,  1305, 13605,\n",
      "          3415,   176,   102,   389,  9324,    19,  5434,   107, 13659,   485,\n",
      "           114, 13605,   911,    13,  1458,    38,    13,   559, 13643, 13660,\n",
      "           559, 13661,   190,  4098, 13662,    17,    13,   559, 13605,  3961,\n",
      "           559,  2932,   211,   432,    99,  3849,   491,   518,  2620,   608,\n",
      "            57,   372,    36,   151,  5433,   559,  1134,    69,    49,   162,\n",
      "           559,    36,   280,   190,  1372,    38,  4237,   211,    24]]) tensor([[ 1,  1,  1,  5, 10,  5,  7,  1,  1,  2, 14, 13,  9,  5,  6,  4, 14,  5,\n",
      "         10,  5,  6,  3,  4,  7,  1, 13,  7,  1,  1,  7,  6,  1,  1,  4,  5,  2,\n",
      "          4,  2,  2,  8, 13, 13,  9,  8,  5,  7,  6,  3,  4,  9,  5, 14,  5,  9,\n",
      "          5, 10,  5, 11,  9,  1,  5, 13,  9,  5,  7,  6,  4,  7,  2,  6,  1,  7,\n",
      "          1, 14,  1,  2,  2,  2,  6,  4,  4,  8,  5,  2,  9,  8,  5, 10,  5,  9,\n",
      "          2,  2,  2,  6,  4,  7,  1,  7,  1,  1,  5, 13,  7,  6,  4,  7,  4, 14,\n",
      "          4,  9,  5,  1,  5,  6,  4,  7,  6,  2,  5,  1,  2,  4,  2,  4,  5,  7,\n",
      "          6,  2,  1,  5,  2,  4,  2, 13,  9,  5, 11, 13, 13,  4,  8,  5,  7,  9,\n",
      "          5,  2,  9,  8, 13, 13,  2,  7,  9,  2,  5,  7,  1,  2,  2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self, pad_unk='<PAD>'):\n",
    "        \"\"\"\n",
    "        A convenience class that can help store a vocabulary\n",
    "        and retrieve indices for inputs.\n",
    "        \"\"\"\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {self.pad_unk: 0}\n",
    "        self.idx2word = [self.pad_unk]\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                self.word2idx[word] = len(self.idx2word)\n",
    "                self.idx2word.append(word)\n",
    "            else:\n",
    "                return self.word2idx[self.pad_unk]\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word(idx)\n",
    "    \n",
    "    def __len__(self): # helpful utility shorthand\n",
    "        return len(self.idx2word)\n",
    "\n",
    "max_len= max([len(x[0]) for x in train_data ])\n",
    "\n",
    "# Your implementation goes here:\n",
    "def prepare(data, word_vocab=None, label_vocab=None):\n",
    "    # Get dims\n",
    "    rows = len(data)\n",
    "    cols = max([len(x[0]) for x in data])\n",
    "    wordmat = torch.zeros((rows, cols), dtype=int)\n",
    "    labelmat = torch.zeros((rows, cols), dtype=int)\n",
    "\n",
    "    # Create vocabs\n",
    "    if word_vocab is None:\n",
    "        allwords = [word for sentence in [datapoint[0] for datapoint in data] for word in sentence] # flattens a 2d list\n",
    "        word_vocab = Vocab()\n",
    "        [word_vocab.getIdx(word, True) for word in allwords]\n",
    "    if label_vocab is None:\n",
    "        alllabels = [label for sentence in [datapoint[1] for datapoint in data] for label in sentence]\n",
    "        label_vocab = Vocab()\n",
    "        [label_vocab.getIdx(label, True) for label in alllabels]\n",
    "    \n",
    "    # Fill matrix with numbers\n",
    "    for i, (words, labels) in enumerate(data):\n",
    "        assert len(words) == len(labels) # these two *should* be the exact same length, right?\n",
    "        # pad lists to fit in the matrix\n",
    "        words += [word_vocab.pad_unk] * (cols - len(words))\n",
    "        labels += [label_vocab.pad_unk] * (cols - len(labels))\n",
    "        # turn into numbers and tensors\n",
    "        words_idx = torch.tensor([word_vocab.getIdx(word) for word in words], dtype=torch.int)\n",
    "        labels_idx = torch.tensor([label_vocab.getIdx(label) for label in labels], dtype=torch.int)\n",
    "        # replace the rows in the matrices\n",
    "        wordmat[i] = words_idx\n",
    "        labelmat[i] = labels_idx\n",
    "    \n",
    "    return wordmat, labelmat, word_vocab, label_vocab # return vocabs too so we can reuse them for dev data.\n",
    "\n",
    "train_X_mat, train_Y_mat, word_vocab, label_vocab = prepare(deepcopy(train_data))\n",
    "print(train_X_mat.shape)\n",
    "# lets find the longest sentence and print that\n",
    "index = [i for i in range(len(train_data)) if len(train_data[i][0]) == train_X_mat.shape[1]]\n",
    "print(train_X_mat[index], train_Y_mat[index])\n",
    "# as expected, every value is filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b) Until now, we have used a batch-size of 1 in our implemented models, meaning that the models weights are updated after each sentence. This is not very computationally efficient. Larger batch-sizes increase the training speed, and can also lead to better performance (more stable training). You can easily convert existing training data to batches, by splitting it up in chunks of `batch_size` sentences, like this (*Make sure you understand this code!*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([200, 100])\n",
      "torch.Size([6, 32, 100])\n",
      "\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 200 instances, 100 features/weights\n",
    "train_y_feats = torch.zeros((200, 100))\n",
    "\n",
    "batch_size = 32\n",
    "num_batches = int(len(train_y_feats)/batch_size)\n",
    "\n",
    "print(num_batches)\n",
    "\n",
    "print(train_y_feats.shape)\n",
    "\n",
    "tmp_feats_batches = train_y_feats[:batch_size*num_batches].view(num_batches,batch_size, 100)\n",
    "\n",
    "# 6 batches with 32 instances with 100 features\n",
    "print(tmp_feats_batches.shape)\n",
    "\n",
    "print()\n",
    "for feats_batch in tmp_feats_batches:\n",
    "    print(feats_batch.shape)\n",
    "    # Here you can call forward/calculate the loss etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this throws away a tiny part of the data (the last `len(tmp_feats)%batch_size`=6 samples), an alternative would be to pad, and ignore the padded part of the last batch for the loss. For the following assignments you can leave the remaining samples out (note that the dev set is dividable by 16 in this case). Furthermore, note that PyTorch supports a more advanced method for batching: [data loaders](https://pytorch.org/docs/stable/data.html), which we will not cover in this course (but you can use them for the final project).\n",
    "\n",
    "Convert your training data and labels to batches of batch size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 batches\n",
      "torch.Size([783, 16, 159])\n",
      "Lost 15 datapoints\n"
     ]
    }
   ],
   "source": [
    "# Your implementation goes here:\n",
    "batch_size = 16\n",
    "num_batches = int(len(train_X_mat)/batch_size)\n",
    "\n",
    "print(f\"{num_batches} batches\")\n",
    "train_X_batches = train_X_mat[:batch_size*num_batches].view(num_batches, batch_size, train_X_mat.shape[1])\n",
    "train_Y_batches = train_Y_mat[:batch_size*num_batches].view(num_batches, batch_size, train_X_mat.shape[1])\n",
    "print(train_X_batches.shape)\n",
    "print(f\"Lost {train_X_mat.shape[0] - train_X_batches.shape[0]*batch_size} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,  ...,   0,   0,   0],\n",
       "        [ 25,  26,  27,  ...,   0,   0,   0],\n",
       "        [ 41,   4,  42,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [180, 181,  12,  ...,   0,   0,   0],\n",
       "        [190, 182,  69,  ...,   0,   0,   0],\n",
       "        [ 26, 202,  69,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_batches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a) Implement a POS tagger model in Pytorch using a [`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) layer for word representations and a [`torch.nn.RNN`](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) layer. You can use a [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer for prediction of the label. Train this tagger on the language identification data, and evaluate its performance. Note that during each training step, you now get the predictions and loss on a whole batch directly. Use the following hyperparameters: 5 epochs over the full training data, word embeddings dimension: 100, rnn dimension of 50, learning rate of 0.01 in an [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and a [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "\n",
    "Hints:\n",
    "* **Set batch_first to true!**, as explained on the [`torch.nn.RNN`](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) page. By default the RNN expects the input to be in the shape: `(seq_len, batch, rnn_dim)`, when it is set to true it should be: `(batch, seq_len, rnn_dim)`.\n",
    "* Training an RNN is generally much slower compared to the machine learning models we implemented before on this data, so we suggest to start with only a sub-part of the data, like 100 or 1,000 sentences. It is also ok to use only 1,000 sentences for your final model (or use the HPC to train the full model).\n",
    "* To calculate the cross entropy loss, we need the predictions to be in the first dimension. We can convert the predictions values from our model (16\\*159\\*18 for 1 batch) to a flatter representation (2544\\*18) by using: `.view(BATCH_SIZE * max_len, -1)`. Of course, we also have to adapt the labels from 16\\*159 to 2544\\*1.\n",
    "\n",
    "For more information on how to implement a Pytorch module, we refer to the code used to obtain the weights in the assignment of week 3 (`week4/train_ff.py`), and the following tutorial series: https://pytorch.org/tutorials/beginner/nlp/index.html (especially the 2nd and 4th tutorials are relevant). You can use the code below as a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, batch 783/783. Current loss: 2912.4770507812575\n",
      "Epoch 2/5, batch 783/783. Current loss: 3222.5026855468755\n",
      "Epoch 3/5, batch 783/783. Current loss: 4062.1633300781255\n",
      "Epoch 4/5, batch 783/783. Current loss: 4184.4956054687555\n",
      "Epoch 5/5, batch 783/783. Current loss: 4378.6992187537555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaggerModel(\n",
       "  (embedding): Embedding(19671, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 50, batch_first=True)\n",
       "  (out): Linear(in_features=50, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "DIM_EMBEDDING = 100\n",
    "RNN_HIDDEN = 50\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "\n",
    "class TaggerModel(torch.nn.Module):\n",
    "    def __init__(self, nwords, ntags):\n",
    "        super(TaggerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(nwords, DIM_EMBEDDING, padding_idx=0)\n",
    "        self.rnn = nn.RNN(DIM_EMBEDDING, RNN_HIDDEN, batch_first=True)\n",
    "        self.out = nn.Linear(RNN_HIDDEN, ntags)\n",
    "        \n",
    "    def forward(self, inputData):\n",
    "        embedded = self.embedding(inputData)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        predictions = self.out(outputs)\n",
    "        return predictions\n",
    "\n",
    "        \n",
    "model = TaggerModel(len(word_vocab), len(label_vocab))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    # reset the gradient\n",
    "    model.zero_grad()\n",
    "    # loop over batches\n",
    "    for i, (X, Y) in enumerate(zip(train_X_batches, train_Y_batches)):\n",
    "        # Y.shape = [16, 159], 16 sentences, 159 \"words\" (most are pads)\n",
    "        probs: torch.Tensor = model.forward(X.type(torch.int))\n",
    "        # predicted_values.rhape = [16, 159, 18], 16 sentences, 159 \"words\", 18 possible labels per word (one prediction per label)\n",
    "        preds, indices = probs.max(dim=2)\n",
    "        # calculate loss (and print)\n",
    "        Yflat = Y.view((BATCH_SIZE * max_len)) # flattes into 16 * 159\n",
    "        probsflat = probs.view((BATCH_SIZE * max_len, -1)) # flattens into 16 * 159, 18\n",
    "        loss = loss_function(probsflat, Yflat)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, batch {i+1}/{num_batches}. Current loss: {loss.item()}\", end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "# wth why did the loss increate with every epoch. Does it actually represent accuracy or something or did I accidentally lobotomise my model somehow\n",
    "\n",
    "# set to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b) Now evaluate the tagger on the dev data (`pos-data/en_ewt-dev.conll`) with accuracy (make sure to not count the padding tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 75])\n",
      "torch.Size([2000, 75])\n",
      "tensor(0.0858)\n"
     ]
    }
   ],
   "source": [
    "dev_X_mat, dev_Y_mat, _, _ = prepare(dev_data, word_vocab=word_vocab, label_vocab=label_vocab)\n",
    "m = nn.Softmax(dim=2)\n",
    "y_prob = m(model(dev_X_mat))\n",
    "probs, preds = y_prob.max(dim=2)\n",
    "print(preds.shape)\n",
    "print(dev_Y_mat.shape)\n",
    "y_pred = preds\n",
    "y_true = dev_Y_mat\n",
    "\n",
    "correct = sum(torch.sum(y_pred == y_true, dim=1))\n",
    "print(correct / (2000 * 75))\n",
    "# thats not great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Bi-LSTM for language classification\n",
    "\n",
    "In assignments for this lecture we are going to implement an LSTM classifier in Pytorch including dropout layers, and train it for the task of topic classification.\n",
    "\n",
    "You can use the following function for data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topics(path):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for lineIdx, line in enumerate(open(path)):\n",
    "        tok = line.strip().split('\\t')\n",
    "        labels.append(tok[0])\n",
    "        text.append(tok[1].split(' '))\n",
    "    return text, labels\n",
    "\n",
    "topic_train_text, topic_train_labels = load_topics('topic-data/train.txt')\n",
    "topic_dev_text, topic_dev_labels = load_topics('topic-data/dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a Bi-LSTM in Pytorch\n",
    "\n",
    "* a) Convert the data to a format that can be used in a Pytorch module. In this assignment, we can cap the size of an utterance, as each utterance only needs 1 label. Use a maximum length of 32 words, for longer sentences, only keep the first 32 words. A special `<PAD>` token can be used for padding for sentences shorter as 32 words. For the unknown words in the test set, you can use the `<PAD>` token as well.\n",
    "\n",
    "**hint**: the shape of the training data should be 13,000 by 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2,     3,  ...,     0,     0,     0],\n",
      "        [   17,    18,    19,  ...,     0,     0,     0],\n",
      "        [   31,    32,    33,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  418,   408,    57,  ...,     0,     0,     0],\n",
      "        [25643,   308,   233,  ...,   138,  3846,   279],\n",
      "        [25644,    40,  8349,  ...,  1638, 11782, 25648]], dtype=torch.int32)\n",
      "torch.Size([13000, 32])\n",
      "tensor([1, 1, 1,  ..., 3, 2, 2])\n",
      "torch.Size([13000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Your implementation goes here:\n",
    "\"\"\"\n",
    "I'd like to take this moment to mention the following like, found in the week 3 exercises:\n",
    "> # This is the definition of an FNN model in PyTorch, and can mostly be ignored for now.\n",
    "> # We will focus on how to create Torch models in week 5\n",
    "The name of this file is \"week4.ipynb\". We are now being told to create PyTorch models from scratch, a week before we're meant to be learning about them. I have no idea what I'm doing.\n",
    "\"\"\"\n",
    "# anyway, doesn't even mentino what data we're meant to be using here. Guess I'll have to assume it's `topic-data`?\n",
    "train_y, train_x = read_conll_file(\"topic-data/train.txt\")[0]\n",
    "dev_y, dev_x = read_conll_file(\"topic-data/dev.txt\")[0]\n",
    "# split words\n",
    "train_X = [sentence.split() for sentence in train_x]\n",
    "dev_X = [sentence.split() for sentence in dev_x]\n",
    "# Limit to 32 words\n",
    "train_X = [words[:32] for words in train_X]\n",
    "dev_X = [words[:32] for words in train_X]\n",
    "# Pad\n",
    "for i in range(len(train_X)):\n",
    "    train_X[i] += [\"<PAD>\"] * (32 - len(train_X[i]))\n",
    "for i in range(len(dev_X)):\n",
    "    dev_X[i] += [\"<PAD>\"] * (32 - len(dev_X[i]))\n",
    "# Build vocab\n",
    "word_vocab = Vocab()\n",
    "label_vocab = Vocab()\n",
    "[word_vocab.getIdx(word, add=True) for words in train_X for word in words]\n",
    "label_idxs = [label_vocab.getIdx(label, add=True) for label in train_y]\n",
    "\n",
    "# Build tensors\n",
    "train_X_mat = torch.zeros((len(train_X), 32), dtype=torch.int)\n",
    "for i, words in enumerate(train_X):\n",
    "    idxs = [word_vocab.getIdx(word) for word in words]\n",
    "    train_X_mat[i] = torch.tensor(idxs, dtype=torch.int)\n",
    "train_y_mat = torch.tensor(label_idxs)\n",
    "\n",
    "print(train_X_mat)\n",
    "print(train_X_mat.shape)\n",
    "print(train_y_mat)\n",
    "print(train_y_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b) Convert your input into batches of size 64, similar as you did in assignment 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 batches\n",
      "torch.Size([203, 64, 32])\n",
      "torch.Size([203, 64])\n",
      "Lost 8 datapoints\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_batches = int(len(train_X_mat)/batch_size)\n",
    "\n",
    "print(f\"{num_batches} batches\")\n",
    "train_X_batches = train_X_mat[:batch_size*num_batches].view(num_batches, batch_size, train_X_mat.shape[1])\n",
    "train_y_batches = train_y_mat[:batch_size*num_batches].view(num_batches, batch_size)\n",
    "print(train_X_batches.shape)\n",
    "print(train_y_batches.shape)\n",
    "\n",
    "print(f\"Lost {train_X_mat.shape[0] - train_X_batches.shape[0]*batch_size} datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* c) Implement a classification model in Pytorch using a [`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) layer and a [`torch.nn.LSTM`](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) layer. Train this classification model on the language identification data, and evaluate its performance. Note that during each training step, you now get the predictions and loss on a whole batch directly. Use the following hyperparameters: 5 epochs over the full training data, word embeddings dimension: 100, lstm dimension of 50, learning rate of 0.01 in an [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and a [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "\n",
    "Hints:\n",
    "* see also the hints for assignment2a\n",
    "* Set bidirectional=True for the LSTM layer (so that we are training a Bi-LSTM), note that the input dimensions of the next layer should then be lstm_dim*2. \n",
    "* We use words as inputs, and need only one label per sentence, so you should use the output of the last item from the forward layer, and the output of the first item for the backward layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thore\\miniconda3\\envs\\nlpdl\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n",
      "torch.Size([64, 32, 100])\n",
      "torch.Size([64, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(25649, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 50, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint: In torch, the BiLSTM returns a concatenation of the forward and \n",
    "# backward layer. Here is an example of how these can be extracted again\n",
    "#     backward_out = bilstm_out[:,0,-size:].squeeze()\n",
    "#     forward_out = bilstm_out[:,-1,:size].squeeze()\n",
    "\n",
    "# I am taking *big* inspiration from https://github.com/bentrevett/pytorch-pos-tagging/blob/master/1_bilstm.ipynb\n",
    "DIM_EMBEDDING = 100\n",
    "LSTM_HIDDEN = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "\n",
    "class BiLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, nwords) -> None:\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(nwords, DIM_EMBEDDING, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(DIM_EMBEDDING, LSTM_HIDDEN, bidirectional=True)\n",
    "    \n",
    "    def forward(self, inputData):\n",
    "        embedded = self.embedding(inputData)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs\n",
    "\n",
    "model = BiLSTMClassifier(len(word_vocab))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0, reduce='sum')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    for i, (X, y) in enumerate(zip(train_X_batches, train_y_batches)):\n",
    "        probs = model.forward(X.type(torch.int))\n",
    "        # okay so the output here is the y value for every word from start to and + every word from end to start.\n",
    "        # but 50 times each, because thats the output dimension. That means I have to turn a 32 * 100 matrix into a single value?\n",
    "        # or at least into N values where N=number of labels. I have no idea how to do that. We were not told how to do that.\n",
    "        # Therefore I give up. I'll ask about it during the next exercise class or smthn.\n",
    "        print(probs.shape)\n",
    "        print(X.shape)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* d) Add a `torch.nn.Dropout` layer with a masking probability of 0.2 between the word embeddings and the LSTM layer and\n",
    "  another dropout layer with a masking probability of 0.3 between the LSTM layer and the output layer. Evaluate the\n",
    "  performance again, is the performance higher?, why would this be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media1.tenor.com/m/pgQLrCGpKKYAAAAd/cat-blueberry.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
