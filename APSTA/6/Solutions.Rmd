---
title: "APSTA Week 06 Exercises"
output: document_pdf
---
1.  
Sum them, they are all 0.25  
  
2.  
a) Double integral!
X+Y<1 => Y<1-X, so Y goes from 0 to 1-X
$$
\begin{aligned}
\int_0^1 \int_0^{1-x}\ f(x,y)\ dydx &=... \\
&=\left[\frac{1}{2}cx^2-\frac{1}{3}cx^3+x-\frac{1}{2}x^2\right]_0^{x=1} \\
&=\frac{1}{2}c-\frac{1}{3}c+1-\frac{1}{2} \\
&=\frac{1}{6}c+\frac{1}{2}
\end{aligned}
$$
entire integral has to be 1, c=3 (why does the integral have to be 1?)
b) marginal distribution
$$
\begin{aligned}
f_X(x)&=\int_{-\infty}^\infty f(x,y)dy \\
&=\int_0^{1-x}3x+1dy \\
&=3xy+y]_0^{y=1-x} \\
&=(3x)(1-x)+(1-x)=-3x^2+2x+1
\end{aligned}
$$
c) $P(Y<2X^2)$
with integrals you take the area under so we can plot the function 2X^2. They intercept somewhere (Y=1-X). Take the two integrals individually and add them together, from X=0->1/2, and X=1/2->1
$$
\begin{aligned}
&\int_0^{\frac{1}{2}}\int_0^{2X^2} 3x+1dydx+\int_{\frac{1}{2}}^1\int_0^{1-X}3x+1dydx \\
&=\frac{17}{46}+\frac{3}{8}=\frac{53}{96}
\end{aligned}
$$
3. covariance
|      |      | 0.25 |
|      |      | 0.25 |
| 0.25 | 0.25 |      |
$E[X]=1\cdot0.25+2\cdot0.25+3\cdot0.25+4\cdot0.5=2.5$
$E[Y]=2.5$
$e[XY]=6.25$
$Cov(X,Y)=E[XY]-E[X]Y[X]=0$
$$
g(x,y)=x\cdot y\ \ \ g:\mathbb{R}^2\to\mathbb{R} \\
E[XY]=\sum_{x\in R_X}\sum_{y\in R_Y}\ g(x,y)p_X,Y(x,y)=\sum_{x\in R_X}\sum_{y\in R_Y} (x\cdot y) p_{X,Y}(x,y)=6.25
$$
4. Correlation
a)
```{r}
library(UsingR)
plot(normtemp$temperature, normtemp$hr)
```
```{r}
cor(normtemp$temperature, normtemp$hr)
```

```{r}
nym.2002
plot(nym.2002$age, nym.2002$time)
```

```{r}
cor(nym.2002$age, nym.2002$time)
```

```{r}
cor(batting$SO,batting$HR)
```

```{r}
plot(batting$SO, batting$HR)
```

5. Cov, Cor and Ind
```{r}
load("mypnts.Rdata")
plot(mypnts$x,mypnts$y)
```
```{r}
cor(mypnts$x,mypnts$y)
```

```{r}
cov(mypnts)
```
x has a variance of 64, y 388,x and y have covariance -162.
Illustrates that the scalres are hard to imagine.  
c) 
```{r}
a <- 0.07
b <- 0
c <- 1
d <- 0.42
xm <- a*mypnts$x + b*mypnts$y
ym <- c*mypnts$x + d*mypnts$y
plot(xm, ym)
```

```{r}
cov(data.frame(xm, ym))
```
correlation gone
whitening: transform our dataset in a way that empirical covariance matrix is the identity matrix (not quite there, but we're on the way).
Rotate to make independent, not just uncorrelated.
NOTE: Difference between correlation and independence. In the square, we learn as x increases, the range of y decreases.